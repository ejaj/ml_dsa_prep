{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spam Detection Using the Unigram Model with Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(model_name=\"bert-base-uncased\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(corpus):\n",
    "    words = []\n",
    "    for sentence in corpus:\n",
    "        words.extend(sentence.split())  # Tokenize based on spaces\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_probabilities(word_counts, total_words):\n",
    "    return {word: count / total_words for word, count in word_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(tokenizer, sentence):\n",
    "    return tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data['text'].tolist(), data['label'].tolist()  # Text and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_probability(sentence, word_probabilities):\n",
    "    words = sentence.split()  # Tokenize the sentence into words\n",
    "    sentence_probability = 1.0\n",
    "    for word in words:\n",
    "        word_prob = word_probabilities.get(word.lower(), 0)  # Default to 0 if word is OOV\n",
    "        sentence_probability *= word_prob\n",
    "    return sentence_probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(sentence, word_probabilities, threshold=0.01):\n",
    "    sentence_prob = calculate_sentence_probability(sentence, word_probabilities)\n",
    "    if sentence_prob > threshold:\n",
    "        return \"Spam\"\n",
    "    else:\n",
    "        return \"Ham\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unigram_model(training_file):\n",
    "    # Load training data\n",
    "    texts, labels = load_data(training_file)\n",
    "\n",
    "    # Build vocabulary and calculate word probabilities\n",
    "    word_counts = build_vocabulary(texts)\n",
    "    total_words = sum(word_counts.values())\n",
    "    word_probabilities = calculate_word_probabilities(word_counts, total_words)\n",
    "\n",
    "    return word_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_file, word_probabilities):\n",
    "    texts, labels = load_data(test_file)\n",
    "\n",
    "    correct = 0\n",
    "    total = len(texts)\n",
    "\n",
    "    for text, true_label in zip(texts, labels):\n",
    "        predicted_label = classify_message(text, word_probabilities)\n",
    "        if predicted_label == \"Spam\" and true_label == 1:\n",
    "            correct += 1\n",
    "        elif predicted_label == \"Ham\" and true_label == 0:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "train_file = \"data/spam_detection_train.csv\"\n",
    "test_file = \"data/spam_detection_test.csv\"\n",
    "word_probabilities = train_unigram_model(train_file)\n",
    "test_model(test_file, word_probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
